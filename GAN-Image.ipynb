{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division \n",
    "import time \n",
    " \n",
    "import tarfile\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg \n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras import Model, Sequential  \n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Activation, ZeroPadding2D, UpSampling2D, Reshape, BatchNormalization, Flatten, Dropout  \n",
    "from tensorflow.keras.layers import LeakyReLU \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.optimizers import Adam "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN class for image generation which mimic the X_train, an array of imgs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 200\n",
    "        self.img_cols = 360\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "        print(self.img_cols)\n",
    "        \n",
    "        optimizer = Adam(0.002,0.5)\n",
    "        \n",
    "        #Build and compile the discriminator \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        #Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        \n",
    "        #The generator takes noise as input and generates images \n",
    "        z = Input(shape=(self.latent_dim))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        # For the combined model we will only train the generator \n",
    "        self.discriminator.trainable = False\n",
    "        validity = self.discriminator(img)\n",
    "        \n",
    "        #Combined model (stacked generator and discriminator)\n",
    "        #Train generator to fool the discriminator\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "    def build_generator(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(256, input_shape = (self.latent_dim,)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "        print('Model summary for Generator')\n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation = 'sigmoid'))\n",
    "        print('Model summary for Discriminator')\n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "        # discriminator ouputs two entries, one validity and one accuracy matrix\n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def train(self, epochs, batch_size=2, sample_interval=50):\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.normal(0,1,(batch_size, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            # d_loss consist of two entry, first one loss, second one accuracy matrix\n",
    "            d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "            # Train generator, such that the discriminator gets fooled\n",
    "            noise = np.random.normal(0,1,(batch_size, self.latent_dim))\n",
    "            g_loss = self.combined.train_on_batch(noise,valid)\n",
    "            # plot progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "            \n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r*c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5*gen_imgs + 0.5\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt,:,:])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        # the directory here is wrong\n",
    "        fig.savefig(\"/Users/yuf/Desktop/Implementation/GAN/Trained_Bab/%d.png\" % epoch)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n",
      "Model summary for Discriminator\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_14 (Flatten)         (None, 216000)            0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 512)               110592512 \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_83 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_84 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 110,724,097\n",
      "Trainable params: 110,724,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model summary for Generator\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_129 (Dense)            (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_85 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_86 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_87 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 216000)            221400000 \n",
      "_________________________________________________________________\n",
      "reshape_13 (Reshape)         (None, 200, 360, 3)       0         \n",
      "=================================================================\n",
      "Total params: 222,089,920\n",
      "Trainable params: 222,086,336\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan_ksgk = GAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_ksgk.train(epochs=1000, batch_size=4, sample_interval=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
